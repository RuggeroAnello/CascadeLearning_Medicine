{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Create a test.csv from train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows in train: 181458\n",
      "# of rows in valid: 9551\n",
      "# of rows in ap_train: 153556\n",
      "# of rows in ap_valid: 8034\n",
      "# of rows in pa_train: 27902\n",
      "# of rows in pa_valid: 1517\n"
     ]
    }
   ],
   "source": [
    "cwd_path = Path.cwd()\n",
    "path = cwd_path.parent.joinpath(\"data\")\n",
    "\n",
    "# Load the train.csv file as \"data_df\"\n",
    "data_df = pd.read_csv(os.path.join(path, r'unprocessed\\train.csv'))\n",
    "\n",
    "# Defining path_unbalanced\n",
    "path_splitted = path.joinpath(\"splitted\")\n",
    "\n",
    "# Step 1: Perform a 95/5 Train-Test Split without any balancing \n",
    "train_df, valid_df = train_test_split(\n",
    "    data_df, \n",
    "    test_size=0.05, random_state=42, shuffle=True)\n",
    "\n",
    "# Step 2: Split data_df into ap and pa subsets\n",
    "ap_df = data_df[data_df['AP/PA'] == 'AP']\n",
    "pa_df = data_df[data_df['AP/PA'] == 'PA']\n",
    "\n",
    "# Step 3: Split ap_df into train_ap and valid_ap\n",
    "train_ap = ap_df[ap_df.index.isin(train_df.index)]\n",
    "valid_ap = ap_df[ap_df.index.isin(valid_df.index)]\n",
    "\n",
    "# Step 4: Split pa_df into train_pa and valid_pa\n",
    "train_pa = pa_df[pa_df.index.isin(train_df.index)]\n",
    "valid_pa = pa_df[pa_df.index.isin(valid_df.index)]\n",
    "\n",
    "print('# of rows in train:', len(train_df))\n",
    "print('# of rows in valid:', len(valid_df))\n",
    "print('# of rows in ap_train:', len(train_ap))\n",
    "print('# of rows in ap_valid:', len(valid_ap))\n",
    "print('# of rows in pa_train:', len(train_pa))\n",
    "print('# of rows in pa_valid:', len(valid_pa))\n",
    "\n",
    "# Optional: Save the resulting DataFrames to CSV files\n",
    "path = \"data\"  # Define your directory path\n",
    "\n",
    "train_df.to_csv(os.path.join(path_splitted, 'train.csv'), index=False)\n",
    "valid_df.to_csv(os.path.join(path_splitted, 'valid.csv'), index=False)\n",
    "\n",
    "train_ap.to_csv(os.path.join(path_splitted, 'ap_train.csv'), index=False)\n",
    "valid_ap.to_csv(os.path.join(path_splitted, 'ap_valid.csv'), index=False)\n",
    "\n",
    "train_pa.to_csv(os.path.join(path_splitted, 'pa_train.csv'), index=False)\n",
    "valid_pa.to_csv(os.path.join(path_splitted, 'pa_valid.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "personalized_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
