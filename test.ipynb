{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Testing\n",
                "\n",
                "This notebook includes the execution of the testing for trained models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import torch\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "import torchvision.transforms as transforms\n",
                "\n",
                "from model.one_model.one_stage_models import ResNet50OneStage, ResNet18OneStage\n",
                "from model.multi_stage_model.multi_stage_model import ThreeStageModelFrontalLateralAPPA, TwoStageModelAPPA, TwoStageModelFrontalLateral\n",
                "from data.dataset import CheXpertDataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "%matplotlib inline\n",
                "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
                "\n",
                "\n",
                "os.environ['KMP_DUPLICATE_LIB_OK']='True' # To prevent the kernel from dying."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Load result.csv file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_xls = \"C:/Users/flobr/OneDrive/Uni/Informatik_Master/ADLM/results.xlsx\"\n",
                "result = pd.read_excel(result_xls, sheet_name='Sheet1')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Class weights: [np.float64(3.0794415416798357), np.float64(2.9201511490782153), np.float64(3.6933892622193722), np.float64(5.873849311314257), np.float64(1.674130760975404)]\n",
                        "Test dataset size: 4482\n"
                    ]
                }
            ],
            "source": [
                "params_transform = {\n",
                "    \"resize\": (256, 256),\n",
                "}\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize(params_transform[\"resize\"]),\n",
                "    transforms.ToTensor(),\n",
                "])\n",
                "\n",
                "targets = {\n",
                "            # \"sex\": 1,\n",
                "            # \"age\": 2,\n",
                "            # \"frontal/lateral\": 3,\n",
                "            # \"ap/pa\": 4,\n",
                "            # \"no_finding\": 5,\n",
                "            # \"enlarged_cardiomediastinum\": 6,\n",
                "            \"cardiomegaly\": 7,\n",
                "            # \"lung_opacity\": 8,\n",
                "            # \"lung_lesion\": 9,\n",
                "            \"edema\": 10,\n",
                "            \"consolidation\": 11,\n",
                "            # \"pneumonia\": 12,\n",
                "            \"atelectasis\": 13,\n",
                "            # \"pneumothorax\": 14,\n",
                "            \"pleural_effusion\": 15,\n",
                "            # \"pleural_other\": 16,\n",
                "            # \"fracture\": 17,\n",
                "            # \"support_devices\": 18,\n",
                "            # \"fronal_lateral_map\": 21,\n",
                "            # \"ap/pa map\": 22,\n",
                "        }\n",
                "\n",
                "csv_file = \"data/90_5_5/test_balanced.csv\"\n",
                "\n",
                "# If you want to test the model on a subset of the labels you can specify the labels here. The labels are the relative positions compared to the labels used in the training.\n",
                "test_labels = None\n",
                "\n",
                "# For All Label Trainings\n",
                "#test_labels = [\n",
                "#    2, # Cardiomegaly is the third element in all labels testing\n",
                "#    5, # Edema is the sixth element in all labels testing\n",
                "#    7, # Consolidation is the eighth element in all labels testing\n",
                "#    9, # Atelectasis is the tenth element in all labels testing\n",
                "#    11, # Pleural Effusion is the twelfth element in all labels testing\n",
                "#]\n",
                "\n",
                "# For 5 Label Trainings\n",
                "#test_labels = [\n",
                "#  0, # Cardiomegaly is the third element in all labels testing\n",
                "#  1, # Edema is the sixth element in all labels testing\n",
                "#  2, # Consolidation is the eighth element in all labels testing\n",
                "#  3, # Atelectasis is the tenth element in all labels testing\n",
                "#  4, # Pleural Effusion is the twelfth element in all labels testing\n",
                "#]\n",
                "\n",
                "test_dataset = CheXpertDataset(\n",
                "    csv_file=csv_file,\n",
                "    root_dir=\"../image_data/\",\n",
                "    targets=targets,\n",
                "    transform=transform,\n",
                ")\n",
                "print(f\"Test dataset size: {len(test_dataset)}\")\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# One stage model\n",
                "\n",
                "Testing of the one stage model.\n",
                "\n",
                "## Define model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    \"train_transfrom\": params_transform,\n",
                "    \"lr\": 0.001,\n",
                "    \"save_epoch\": 5,\n",
                "    \"batch_size\": 256,\n",
                "    \"num_epochs\": 100,\n",
                "    \"input_channels\": 1,\n",
                "    \"optimizer\": \"adam\",\n",
                "    \"num_workers\": 0,\n",
                "    \"loss_fn\": \"multilabel_focal_loss\",\n",
                "    \"metrics\": [\"accuracy\",\n",
                "            \"precision\",\n",
                "            \"recall\",\n",
                "            \"confusion_matrix\",\n",
                "            \"auc\",\n",
                "            \"auroc\",\n",
                "            \"multilabel_accuracy\",\n",
                "            \"multilabel_auprc\",\n",
                "            \"multilabel_precision_recall_curve\",\n",
                "            \"mcc\"],\n",
                "    \"confidence_threshold\": 0.5,\n",
                "}\n",
                "\n",
                "family = \"Resnet50_Baseline\"\n",
                "name = \"best_model_71\"\n",
                "\n",
                "weights = f\"final_models/final_90_5_5/{family}/{name}.pth\"\n",
                "\n",
                "model = ResNet18OneStage(params=params, targets=targets, input_channels=params['input_channels'])\n",
                "model.load_model(weights)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing one stage model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:14<00:00,  1.22it/s, test_loss=0.116757]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test loss: 0.11675725394844588\n",
                        "Test cardiomegaly accuracy: 0.8728246092796326\n",
                        "Test cardiomegaly precision: 0.38957056403160095\n",
                        "Test cardiomegaly recall: 0.2550200819969177\n",
                        "Test cardiomegaly auroc: 0.769158209141788\n",
                        "Test cardiomegaly auc: 0.22163620591163635\n",
                        "Test cardiomegaly confusion_matrix: tensor([[3785.,  199.],\n",
                        "        [ 371.,  127.]])\n",
                        "Test edema accuracy: 0.680499792098999\n",
                        "Test edema precision: 0.8826073408126831\n",
                        "Test edema recall: 0.7308774590492249\n",
                        "Test edema auroc: 0.5696341328933052\n",
                        "Test edema auc: 0.02819528803229332\n",
                        "Test edema confusion_matrix: tensor([[ 193.,  380.],\n",
                        "        [1052., 2857.]])\n",
                        "Test consolidation accuracy: 0.9277108311653137\n",
                        "Test consolidation precision: 0.1551724076271057\n",
                        "Test consolidation recall: 0.03169013932347298\n",
                        "Test consolidation auroc: 0.6524476779687175\n",
                        "Test consolidation auc: 0.10357023775577545\n",
                        "Test consolidation confusion_matrix: tensor([[4149.,   49.],\n",
                        "        [ 275.,    9.]])\n",
                        "Test atelectasis accuracy: 0.9863899946212769\n",
                        "Test atelectasis precision: 0.9925892949104309\n",
                        "Test atelectasis recall: 0.9937050342559814\n",
                        "Test atelectasis auroc: 0.4880382458738891\n",
                        "Test atelectasis auc: 0.004201854113489389\n",
                        "Test atelectasis confusion_matrix: tensor([[1.0000e+00, 3.3000e+01],\n",
                        "        [2.8000e+01, 4.4200e+03]])\n",
                        "Test pleural_effusion accuracy: 0.7365015745162964\n",
                        "Test pleural_effusion precision: 0.7785235047340393\n",
                        "Test pleural_effusion recall: 0.3066754937171936\n",
                        "Test pleural_effusion auroc: 0.8159596731771376\n",
                        "Test pleural_effusion auc: 0.5147063732147217\n",
                        "Test pleural_effusion confusion_matrix: tensor([[2837.,  132.],\n",
                        "        [1049.,  464.]])\n",
                        "Test multilabel_accuracy: 0.3969210088253021\n",
                        "Test multilabel_auprc: 0.604101300239563\n",
                        "Test mcc: 0.6890899538993835\n"
                    ]
                }
            ],
            "source": [
                "res = model.test(test_dataset=test_dataset,name=name, test_labels=test_labels)\n",
                "# append two columns: confidence_threshold and test_set to the result\n",
                "res[\"confidence_threshold\"] = params[\"confidence_threshold\"]\n",
                "res[\"test_set\"] = csv_file\n",
                "res[\"family\"] = family\n",
                "\n",
                "result = pd.concat([result, res], ignore_index=True)\n",
                "# write result to excel\n",
                "with pd.ExcelWriter(result_xls, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
                "    result.to_excel(writer, sheet_name=\"Sheet1\", index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Two stage model - AP/PA Split\n",
                "\n",
                "Testing of the two stage model with ap/pa split.\n",
                "\n",
                "## Define model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Class weights: [np.float64(2.9794206294995904), np.float64(3.3538481571785983), np.float64(3.603309595859006), np.float64(6.078663481969815), np.float64(1.355350237982541)]\n",
                        "Test dataset size: 9532\n"
                    ]
                }
            ],
            "source": [
                "params_transform = {\n",
                "    \"resize\": (256, 256),\n",
                "}\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize(params_transform[\"resize\"]),\n",
                "    transforms.ToTensor(),\n",
                "])\n",
                "\n",
                "targets = {\n",
                "            # \"sex\": 1,\n",
                "            # \"age\": 2,\n",
                "            # \"frontal/lateral\": 3,\n",
                "            # \"ap/pa\": 4,\n",
                "            # \"no_finding\": 5,\n",
                "            # \"enlarged_cardiomediastinum\": 6,\n",
                "            \"cardiomegaly\": 7,\n",
                "            # \"lung_opacity\": 8,\n",
                "            # \"lung_lesion\": 9,\n",
                "            \"edema\": 10,\n",
                "            \"consolidation\": 11,\n",
                "            # \"pneumonia\": 12,\n",
                "            \"atelectasis\": 13,\n",
                "            # \"pneumothorax\": 14,\n",
                "            \"pleural_effusion\": 15,\n",
                "            # \"pleural_other\": 16,\n",
                "            # \"fracture\": 17,\n",
                "            # \"support_devices\": 18,\n",
                "            # \"fronal_lateral_map\": 21,\n",
                "            # \"ap/pa map\": 22,\n",
                "        }\n",
                "\n",
                "# If you want to test the model on a subset of the labels you can specify the labels here. The labels are the relative positions compared to the labels used in the training.\n",
                "test_labels = None\n",
                "\n",
                "csv_file = \"data/90_5_5/fr_test.csv\"\n",
                "\n",
                "test_dataset = CheXpertDataset(\n",
                "    csv_file=csv_file,\n",
                "    root_dir=\"../image_data/\",\n",
                "    targets=targets,\n",
                "    transform=transform,\n",
                ")\n",
                "print(f\"Test dataset size: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    \"train_transfrom\": params_transform,\n",
                "    \"lr\": 0.001,\n",
                "    \"save_epoch\": 5,\n",
                "    \"batch_size\": 256,\n",
                "    \"num_epochs\": 100,\n",
                "    \"input_channels\": 1,\n",
                "    \"optimizer\": \"adam\",\n",
                "    \"num_workers\": 0,\n",
                "    \"loss_fn\": \"multilabel_focal_loss\",\n",
                "    \"metrics\": [\"accuracy\",\n",
                "            \"precision\",\n",
                "            \"recall\",\n",
                "            \"confusion_matrix\",\n",
                "            \"auc\",\n",
                "            \"auroc\",\n",
                "            \"multilabel_accuracy\",\n",
                "            \"multilabel_auprc\",\n",
                "            \"multilabel_precision_recall_curve\",\n",
                "            \"mcc\"],\n",
                "    \"confidence_threshold\": 0.5,\n",
                "}\n",
                "\n",
                "name = \"best_model_mcc_pretrained\"\n",
                "\n",
                "family = \"Two_Stage_AP/PA\"\n",
                "\n",
                "weights_first_stage = \"final_models/final_90_5_5/ap-pa_split.pth\"\n",
                "weights_second_stage_ap = \"final_models/final_90_5_5/AP_Pretrained/best_model_mcc_49.pth\"\n",
                "weights_second_stage_pa = \"final_models/final_90_5_5/PA_Pretrained/best_model_mcc_30.pth\"\n",
                "\n",
                "weights = f\"First: {weights_first_stage}, Second AP: {weights_second_stage_ap}, Second PA: {weights_second_stage_pa}\"\n",
                "\n",
                "model = TwoStageModelAPPA(\n",
                "    params=params, \n",
                "    model_ap_pa_classification=weights_first_stage, \n",
                "    model_ap=weights_second_stage_ap, \n",
                "    model_pa=weights_second_stage_pa,\n",
                "    targets=targets,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing two stage model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:27<00:00,  1.37it/s, test_loss=0.100768]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test loss: 0.10076798897900856\n",
                        "Test cardiomegaly accuracy: 0.8692824244499207\n",
                        "Test cardiomegaly precision: 0.4438839852809906\n",
                        "Test cardiomegaly recall: 0.3042351007461548\n",
                        "Test cardiomegaly auroc: 0.7795436989641249\n",
                        "Test cardiomegaly auc: 0.2575719952583313\n",
                        "Test cardiomegaly confusion_matrix: tensor([[7934.,  441.],\n",
                        "        [ 805.,  352.]])\n",
                        "Test edema accuracy: 0.7880822420120239\n",
                        "Test edema precision: 0.9243366718292236\n",
                        "Test edema recall: 0.8364158272743225\n",
                        "Test edema auroc: 0.6307223815414149\n",
                        "Test edema auc: 0.030435457825660706\n",
                        "Test edema confusion_matrix: tensor([[ 231.,  596.],\n",
                        "        [1424., 7281.]])\n",
                        "Test consolidation accuracy: 0.881766676902771\n",
                        "Test consolidation precision: 0.14501510560512543\n",
                        "Test consolidation recall: 0.14611871540546417\n",
                        "Test consolidation auroc: 0.6623789739961841\n",
                        "Test consolidation auc: 0.051567938178777695\n",
                        "Test consolidation confusion_matrix: tensor([[8309.,  566.],\n",
                        "        [ 561.,   96.]])\n",
                        "Test atelectasis accuracy: 0.949328601360321\n",
                        "Test atelectasis precision: 0.9937390089035034\n",
                        "Test atelectasis recall: 0.955030083656311\n",
                        "Test atelectasis auroc: 0.4957533185306321\n",
                        "Test atelectasis auc: 0.003627678845077753\n",
                        "Test atelectasis confusion_matrix: tensor([[2.0000e+00, 5.7000e+01],\n",
                        "        [4.2600e+02, 9.0470e+03]])\n",
                        "Test pleural_effusion accuracy: 0.7016366124153137\n",
                        "Test pleural_effusion precision: 0.6707624197006226\n",
                        "Test pleural_effusion recall: 0.5420061349868774\n",
                        "Test pleural_effusion auroc: 0.7696567297725948\n",
                        "Test pleural_effusion auc: 0.25717243552207947\n",
                        "Test pleural_effusion confusion_matrix: tensor([[4559., 1045.],\n",
                        "        [1799., 2129.]])\n",
                        "Test multilabel_accuracy: 0.3873268961906433\n",
                        "Test multilabel_auprc: 0.6201891303062439\n",
                        "Test mcc: 0.6793495416641235\n"
                    ]
                }
            ],
            "source": [
                "res = model.test(test_dataset=test_dataset,name=name, test_labels=test_labels)\n",
                "# append two columns: confidence_threshold and test_set to the result\n",
                "res[\"confidence_threshold\"] = params[\"confidence_threshold\"]\n",
                "res[\"test_set\"] = csv_file\n",
                "res[\"family\"] = family\n",
                "\n",
                "result = pd.concat([result, res], ignore_index=True)\n",
                "# write result to excel\n",
                "with pd.ExcelWriter(result_xls, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
                "    result.to_excel(writer, sheet_name=\"Sheet1\", index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Two stage model - Frontal/Lateral Split\n",
                "\n",
                "Testing of the two stage model with fronal/lateral split.\n",
                "\n",
                "## Define model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Class weights: [np.float64(2.988169226925719), np.float64(3.256541154492639), np.float64(3.6312276324022994), np.float64(6.081854349242607), np.float64(1.4358135019244247)]\n",
                        "Test dataset size: 11183\n"
                    ]
                }
            ],
            "source": [
                "params_transform = {\n",
                "    \"resize\": (256, 256),\n",
                "}\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize(params_transform[\"resize\"]),\n",
                "    transforms.ToTensor(),\n",
                "])\n",
                "\n",
                "targets = {\n",
                "            # \"sex\": 1,\n",
                "            # \"age\": 2,\n",
                "            # \"frontal/lateral\": 3,\n",
                "            # \"ap/pa\": 4,\n",
                "            # \"no_finding\": 5,\n",
                "            # \"enlarged_cardiomediastinum\": 6,\n",
                "            \"cardiomegaly\": 7,\n",
                "            # \"lung_opacity\": 8,\n",
                "            # \"lung_lesion\": 9,\n",
                "            \"edema\": 10,\n",
                "            \"consolidation\": 11,\n",
                "            # \"pneumonia\": 12,\n",
                "            \"atelectasis\": 13,\n",
                "            # \"pneumothorax\": 14,\n",
                "            \"pleural_effusion\": 15,\n",
                "            # \"pleural_other\": 16,\n",
                "            # \"fracture\": 17,\n",
                "            # \"support_devices\": 18,\n",
                "            # \"fronal_lateral_map\": 21,\n",
                "            # \"ap/pa map\": 22,\n",
                "        }\n",
                "\n",
                "# If you want to test the model on a subset of the labels you can specify the labels here. The labels are the relative positions compared to the labels used in the training.\n",
                "test_labels = None\n",
                "\n",
                "csv_file = \"data/90_5_5/test.csv\"\n",
                "\n",
                "test_dataset = CheXpertDataset(\n",
                "    csv_file=csv_file,\n",
                "    root_dir=\"../image_data/\",\n",
                "    targets=targets,\n",
                "    transform=transform,\n",
                ")\n",
                "print(f\"Test dataset size: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    \"train_transfrom\": params_transform,\n",
                "    \"lr\": 0.001,\n",
                "    \"save_epoch\": 5,\n",
                "    \"batch_size\": 256,\n",
                "    \"num_epochs\": 100,\n",
                "    \"input_channels\": 1,\n",
                "    \"optimizer\": \"adam\",\n",
                "    \"num_workers\": 0,\n",
                "    # BCE with Sigmoid activation function\n",
                "    \"loss_fn\": \"torch.nn.BCEWithLogitsLoss()\",\n",
                "    # For multilabel: MultiLabelSoftMarginLoss\n",
                "    \"metrics\": [\"accuracy\",\n",
                "            \"precision\",\n",
                "            \"recall\",\n",
                "            \"confusion_matrix\",\n",
                "            \"auc\",\n",
                "            \"auroc\",\n",
                "            \"multilabel_accuracy\",\n",
                "            \"multilabel_auprc\",\n",
                "            \"multilabel_precision_recall_curve\",\n",
                "            \"mcc\"],\n",
                "    \"confidence_threshold\": 0.5,\n",
                "}\n",
                "\n",
                "name = \"best_model_mcc_pretrained\"\n",
                "\n",
                "family = \"Two_Stage_Frontal/Lateral\"\n",
                "\n",
                "weights_first_stage = \"final_models/final_90_5_5/fr-lat_split.pth\"\n",
                "weights_second_stage_frontal = \"final_models/final_90_5_5/Fr_Pretrained/best_model_mcc_50.pth\"\n",
                "weights_second_stage_lateral = \"final_models/final_90_5_5/Lat_Pretrained/best_model_mcc_45.pth\"\n",
                "\n",
                "weights = f\"First: {weights_first_stage}, Second Frontal: {weights_second_stage_frontal}, Second Lateral: {weights_second_stage_lateral}\"\n",
                "\n",
                "model = TwoStageModelFrontalLateral(\n",
                "    params=params, \n",
                "    model_frontal_lateral_classification=weights_first_stage,\n",
                "    model_frontal=weights_second_stage_frontal,\n",
                "    model_lateral=weights_second_stage_lateral,\n",
                "    targets=targets,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing two stage model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:30<00:00,  1.42it/s, test_loss=0.420495]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test loss: 0.4204948039883262\n",
                        "Test cardiomegaly accuracy: 0.8810694813728333\n",
                        "Test cardiomegaly precision: 0.513731837272644\n",
                        "Test cardiomegaly recall: 0.23608018457889557\n",
                        "Test cardiomegaly auroc: 0.7749722773454966\n",
                        "Test cardiomegaly auc: 0.3155770003795624\n",
                        "Test cardiomegaly confusion_matrix: tensor([[9535.,  301.],\n",
                        "        [1029.,  318.]])\n",
                        "Test edema accuracy: 0.5477957725524902\n",
                        "Test edema precision: 0.9297590851783752\n",
                        "Test edema recall: 0.5413414835929871\n",
                        "Test edema auroc: 0.6176577623532438\n",
                        "Test edema auc: 0.03343889117240906\n",
                        "Test edema confusion_matrix: tensor([[ 646.,  414.],\n",
                        "        [4643., 5480.]])\n",
                        "Test consolidation accuracy: 0.9146919250488281\n",
                        "Test consolidation precision: 0.16721311211585999\n",
                        "Test consolidation recall: 0.06790945678949356\n",
                        "Test consolidation auroc: 0.6582017688072346\n",
                        "Test consolidation auc: 0.06264714896678925\n",
                        "Test consolidation confusion_matrix: tensor([[10178.,   254.],\n",
                        "        [  700.,    51.]])\n",
                        "Test atelectasis accuracy: 0.9712957143783569\n",
                        "Test atelectasis precision: 0.9938684105873108\n",
                        "Test atelectasis recall: 0.9771459698677063\n",
                        "Test atelectasis auroc: 0.5451460881040495\n",
                        "Test atelectasis auc: 0.001262766309082508\n",
                        "Test atelectasis confusion_matrix: tensor([[2.0000e+00, 6.7000e+01],\n",
                        "        [2.5400e+02, 1.0860e+04]])\n",
                        "Test pleural_effusion accuracy: 0.6931950449943542\n",
                        "Test pleural_effusion precision: 0.7415786981582642\n",
                        "Test pleural_effusion recall: 0.3358379006385803\n",
                        "Test pleural_effusion auroc: 0.7941921081663049\n",
                        "Test pleural_effusion auc: 0.2908720374107361\n",
                        "Test pleural_effusion confusion_matrix: tensor([[6277.,  514.],\n",
                        "        [2917., 1475.]])\n",
                        "Test multilabel_accuracy: 0.27783241868019104\n",
                        "Test multilabel_auprc: 0.619644284248352\n",
                        "Test mcc: 0.6286238431930542\n"
                    ]
                }
            ],
            "source": [
                "res = model.test(test_dataset=test_dataset,name=name, test_labels=test_labels)\n",
                "# append two columns: confidence_threshold and test_set to the result\n",
                "res[\"confidence_threshold\"] = params[\"confidence_threshold\"]\n",
                "res[\"test_set\"] = csv_file\n",
                "res[\"family\"] = family\n",
                "\n",
                "result = pd.concat([result, res], ignore_index=True)\n",
                "# write result to excel\n",
                "with pd.ExcelWriter(result_xls, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
                "    result.to_excel(writer, sheet_name=\"Sheet1\", index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Three stage model - Lateral/AP/PA Split\n",
                "\n",
                "Testing of the three stage model. First stage is the frontal/lateral split, second stage is the ap/pa split and third stage is the multilabel classification of the images.\n",
                "\n",
                "## Define model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Class weights: [np.float64(3.0794415416798357), np.float64(2.9201511490782153), np.float64(3.6933892622193722), np.float64(5.873849311314257), np.float64(1.674130760975404)]\n",
                        "Test dataset size: 4482\n"
                    ]
                }
            ],
            "source": [
                "params_transform = {\n",
                "    \"resize\": (256, 256),\n",
                "}\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize(params_transform[\"resize\"]),\n",
                "    transforms.ToTensor(),\n",
                "])\n",
                "\n",
                "targets = {\n",
                "            # \"sex\": 1,\n",
                "            # \"age\": 2,\n",
                "            # \"frontal/lateral\": 3,\n",
                "            # \"ap/pa\": 4,\n",
                "            # \"no_finding\": 5,\n",
                "            # \"enlarged_cardiomediastinum\": 6,\n",
                "            \"cardiomegaly\": 7,\n",
                "            # \"lung_opacity\": 8,\n",
                "            # \"lung_lesion\": 9,\n",
                "            \"edema\": 10,\n",
                "            \"consolidation\": 11,\n",
                "            # \"pneumonia\": 12,\n",
                "            \"atelectasis\": 13,\n",
                "            # \"pneumothorax\": 14,\n",
                "            \"pleural_effusion\": 15,\n",
                "            # \"pleural_other\": 16,\n",
                "            # \"fracture\": 17,\n",
                "            # \"support_devices\": 18,\n",
                "            # \"fronal_lateral_map\": 21,\n",
                "            # \"ap/pa map\": 22,\n",
                "        }\n",
                "\n",
                "# If you want to test the model on a subset of the labels you can specify the labels here. The labels are the relative positions compared to the labels used in the training.\n",
                "test_labels = None\n",
                "\n",
                "csv_file = \"data/90_5_5/test_balanced.csv\"\n",
                "\n",
                "test_dataset = CheXpertDataset(\n",
                "    csv_file=csv_file,\n",
                "    root_dir=\"../image_data/\",\n",
                "    targets=targets,\n",
                "    transform=transform,\n",
                ")\n",
                "print(f\"Test dataset size: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    \"train_transfrom\": params_transform,\n",
                "    \"lr\": 0.001,\n",
                "    \"save_epoch\": 5,\n",
                "    \"batch_size\": 256,\n",
                "    \"num_epochs\": 100,\n",
                "    \"input_channels\": 1,\n",
                "    \"optimizer\": \"adam\",\n",
                "    \"num_workers\": 0,\n",
                "    \"loss_fn\": \"multilabel_focal_loss\",\n",
                "    \"metrics\": [\"accuracy\",\n",
                "            \"precision\",\n",
                "            \"recall\",\n",
                "            \"confusion_matrix\",\n",
                "            \"auc\",\n",
                "            \"auroc\",\n",
                "            \"multilabel_accuracy\",\n",
                "            \"multilabel_auprc\",\n",
                "            \"multilabel_precision_recall_curve\",\n",
                "            \"mcc\"],\n",
                "    \"confidence_threshold\": 0.5,\n",
                "}\n",
                "\n",
                "name = \"best_model_pretrained\"\n",
                "\n",
                "family = \"Three_Stage\"\n",
                "\n",
                "\n",
                "weights_fr_lat_classification = \"final_models/final_90_5_5/fr-lat_split.pth\"\n",
                "weights_ap_pa_classification = \"final_models/final_90_5_5/ap-pa_split.pth\"\n",
                "weights_frontal_ap = \"final_models/final_90_5_5/AP_Pretrained/best_model_38.pth\"\n",
                "weights_frontal_pa = \"final_models/final_90_5_5/PA_Pretrained/best_model_26.pth\"\n",
                "weights_lateral = \"final_models/final_90_5_5/Lat_Pretrained/best_model_45.pth\"\n",
                "\n",
                "weights = f\"Fr/Lat Classification: {weights_fr_lat_classification}, AP/PA Classification: {weights_ap_pa_classification}, Frontal AP: {weights_frontal_ap}, Frontal PA: {weights_frontal_pa}, Lateral: {weights_lateral}\"\n",
                "\n",
                "\n",
                "model = ThreeStageModelFrontalLateralAPPA(\n",
                "    params=params, \n",
                "    model_frontal_lateral_classification = weights_fr_lat_classification,\n",
                "    model_frontal_ap_pa_classification = weights_ap_pa_classification,\n",
                "    model_frontal_ap = weights_frontal_ap,\n",
                "    model_frontal_pa = weights_frontal_pa,\n",
                "    model_lateral = weights_lateral,\n",
                "    targets=targets,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing three stage model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:13<00:00,  1.30it/s, test_loss=0.396220]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test loss: 0.39622024474067274\n",
                        "Test cardiomegaly accuracy: 0.8846496939659119\n",
                        "Test cardiomegaly precision: 0.4599156081676483\n",
                        "Test cardiomegaly recall: 0.21887549757957458\n",
                        "Test cardiomegaly auroc: 0.760410618377123\n",
                        "Test cardiomegaly auc: 0.28462865948677063\n",
                        "Test cardiomegaly confusion_matrix: tensor([[3856.,  128.],\n",
                        "        [ 389.,  109.]])\n",
                        "Test edema accuracy: 0.7634984254837036\n",
                        "Test edema precision: 0.8811880946159363\n",
                        "Test edema recall: 0.842414915561676\n",
                        "Test edema auroc: 0.5880612021213855\n",
                        "Test edema auc: 0.04004054144024849\n",
                        "Test edema confusion_matrix: tensor([[ 129.,  444.],\n",
                        "        [ 616., 3293.]])\n",
                        "Test consolidation accuracy: 0.9051762819290161\n",
                        "Test consolidation precision: 0.1492537260055542\n",
                        "Test consolidation recall: 0.10563380271196365\n",
                        "Test consolidation auroc: 0.6499586489877809\n",
                        "Test consolidation auc: 0.08941151201725006\n",
                        "Test consolidation confusion_matrix: tensor([[4027.,  171.],\n",
                        "        [ 254.,   30.]])\n",
                        "Test atelectasis accuracy: 0.9437751173973083\n",
                        "Test atelectasis precision: 0.9927195906639099\n",
                        "Test atelectasis recall: 0.9503147602081299\n",
                        "Test atelectasis auroc: 0.6426351565806179\n",
                        "Test atelectasis auc: 0.0026688415091484785\n",
                        "Test atelectasis confusion_matrix: tensor([[3.0000e+00, 3.1000e+01],\n",
                        "        [2.2100e+02, 4.2270e+03]])\n",
                        "Test pleural_effusion accuracy: 0.7661758065223694\n",
                        "Test pleural_effusion precision: 0.7030567526817322\n",
                        "Test pleural_effusion recall: 0.5320554971694946\n",
                        "Test pleural_effusion auroc: 0.8287991109720027\n",
                        "Test pleural_effusion auc: 0.361102819442749\n",
                        "Test pleural_effusion confusion_matrix: tensor([[2629.,  340.],\n",
                        "        [ 708.,  805.]])\n",
                        "Test multilabel_accuracy: 0.42838019132614136\n",
                        "Test multilabel_auprc: 0.6085640788078308\n",
                        "Test mcc: 0.7064830660820007\n"
                    ]
                }
            ],
            "source": [
                "res = model.test(test_dataset=test_dataset,name=name, test_labels=test_labels)\n",
                "# append two columns: confidence_threshold and test_set to the result\n",
                "res[\"confidence_threshold\"] = params[\"confidence_threshold\"]\n",
                "res[\"test_set\"] = csv_file\n",
                "res[\"family\"] = family\n",
                "\n",
                "result = pd.concat([result, res], ignore_index=True)\n",
                "# write result to excel\n",
                "with pd.ExcelWriter(result_xls, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
                "    result.to_excel(writer, sheet_name=\"Sheet1\", index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "personalized_ml",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
