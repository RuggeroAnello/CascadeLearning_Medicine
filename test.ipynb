{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Testing\n",
                "\n",
                "This notebook includes the execution of the testing for trained models."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import torch\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "import torchvision.transforms as transforms\n",
                "\n",
                "from model.one_model.one_stage_models import ResNet50OneStage, ResNet18OneStage\n",
                "from model.multi_stage_model.multi_stage_model import ThreeStageModelFrontalLateralAPPA, TwoStageModelAPPA, TwoStageModelFrontalLateral\n",
                "from data.dataset import CheXpertDataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "%matplotlib inline\n",
                "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
                "\n",
                "\n",
                "os.environ['KMP_DUPLICATE_LIB_OK']='True' # To prevent the kernel from dying."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Load result.csv file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {},
            "outputs": [],
            "source": [
                "result_xls = \"C:/Users/flobr/OneDrive/Uni/Informatik_Master/ADLM/results.xlsx\"\n",
                "result = pd.read_excel(result_xls, sheet_name='Sheet1')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Test Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Class weights: [np.float64(3.1172684010519984), np.float64(2.86429275487946), np.float64(3.807984255408364), np.float64(5.859138095502676), np.float64(1.7632622291880837)]\n",
                        "Test dataset size: 2988\n"
                    ]
                }
            ],
            "source": [
                "params_transform = {\n",
                "    \"resize\": (256, 256),\n",
                "}\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize(params_transform[\"resize\"]),\n",
                "    transforms.ToTensor(),\n",
                "])\n",
                "\n",
                "targets = {\n",
                "            # \"sex\": 1,\n",
                "            # \"age\": 2,\n",
                "            # \"frontal/lateral\": 3,\n",
                "            # \"ap/pa\": 4,\n",
                "            # \"no_finding\": 5,\n",
                "            # \"enlarged_cardiomediastinum\": 6,\n",
                "            \"cardiomegaly\": 7,\n",
                "            # \"lung_opacity\": 8,\n",
                "            # \"lung_lesion\": 9,\n",
                "            \"edema\": 10,\n",
                "            \"consolidation\": 11,\n",
                "            # \"pneumonia\": 12,\n",
                "            \"atelectasis\": 13,\n",
                "            # \"pneumothorax\": 14,\n",
                "            \"pleural_effusion\": 15,\n",
                "            # \"pleural_other\": 16,\n",
                "            # \"fracture\": 17,\n",
                "            # \"support_devices\": 18,\n",
                "            # \"fronal_lateral_map\": 21,\n",
                "            # \"ap/pa map\": 22,\n",
                "        }\n",
                "\n",
                "csv_file = \"data/90_5_5/fr_lat_test_balanced.csv\"\n",
                "\n",
                "# If you want to test the model on a subset of the labels you can specify the labels here. The labels are the relative positions compared to the labels used in the training.\n",
                "test_labels = None\n",
                "\n",
                "# For All Label Trainings\n",
                "#test_labels = [\n",
                "#    2, # Cardiomegaly is the third element in all labels testing\n",
                "#    5, # Edema is the sixth element in all labels testing\n",
                "#    7, # Consolidation is the eighth element in all labels testing\n",
                "#    9, # Atelectasis is the tenth element in all labels testing\n",
                "#    11, # Pleural Effusion is the twelfth element in all labels testing\n",
                "#]\n",
                "\n",
                "# For 5 Label Trainings\n",
                "#test_labels = [\n",
                "#  0, # Cardiomegaly is the third element in all labels testing\n",
                "#  1, # Edema is the sixth element in all labels testing\n",
                "#  2, # Consolidation is the eighth element in all labels testing\n",
                "#  3, # Atelectasis is the tenth element in all labels testing\n",
                "#  4, # Pleural Effusion is the twelfth element in all labels testing\n",
                "#]\n",
                "\n",
                "test_dataset = CheXpertDataset(\n",
                "    csv_file=csv_file,\n",
                "    root_dir=\"../image_data/\",\n",
                "    targets=targets,\n",
                "    transform=transform,\n",
                ")\n",
                "print(f\"Test dataset size: {len(test_dataset)}\")\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# One stage model\n",
                "\n",
                "Testing of the one stage model.\n",
                "\n",
                "## Define model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    \"train_transfrom\": params_transform,\n",
                "    \"lr\": 0.001,\n",
                "    \"save_epoch\": 5,\n",
                "    \"batch_size\": 256,\n",
                "    \"num_epochs\": 100,\n",
                "    \"input_channels\": 1,\n",
                "    \"optimizer\": \"adam\",\n",
                "    \"num_workers\": 0,\n",
                "    \"loss_fn\": \"multilabel_focal_loss\",\n",
                "    \"metrics\": [\"accuracy\",\n",
                "            \"precision\",\n",
                "            \"recall\",\n",
                "            \"confusion_matrix\",\n",
                "            \"auc\",\n",
                "            \"auroc\",\n",
                "            \"multilabel_accuracy\",\n",
                "            \"multilabel_auprc\",\n",
                "            \"multilabel_precision_recall_curve\",\n",
                "            \"mcc\"],\n",
                "    \"confidence_threshold\": 0.5,\n",
                "}\n",
                "\n",
                "family = \"Resnet50_Baseline_Frontal\"\n",
                "name = \"best_model_82\"\n",
                "\n",
                "weights = f\"final_models/final_90_5_5/{family}/{name}.pth\"\n",
                "\n",
                "model = ResNet18OneStage(params=params, targets=targets, input_channels=params['input_channels'])\n",
                "model.load_model(weights)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing one stage model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:09<00:00,  1.22it/s, test_loss=0.125585]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test loss: 0.1255854035694672\n",
                        "Test cardiomegaly accuracy: 0.8872155547142029\n",
                        "Test cardiomegaly precision: 0.41489362716674805\n",
                        "Test cardiomegaly recall: 0.1214953288435936\n",
                        "Test cardiomegaly auroc: 0.7036456891486695\n",
                        "Test cardiomegaly auc: 0.16043971478939056\n",
                        "Test cardiomegaly confusion_matrix: tensor([[2612.,   55.],\n",
                        "        [ 282.,   39.]])\n",
                        "Test edema accuracy: 0.5327978730201721\n",
                        "Test edema precision: 0.8874430656433105\n",
                        "Test edema recall: 0.527251660823822\n",
                        "Test edema auroc: 0.5570139205523108\n",
                        "Test edema auc: 0.02513801120221615\n",
                        "Test edema confusion_matrix: tensor([[ 228.,  173.],\n",
                        "        [1223., 1364.]])\n",
                        "Test consolidation accuracy: 0.9377509951591492\n",
                        "Test consolidation precision: 0.19230769574642181\n",
                        "Test consolidation recall: 0.029411764815449715\n",
                        "Test consolidation auroc: 0.5718594748048261\n",
                        "Test consolidation auc: 0.02827896922826767\n",
                        "Test consolidation confusion_matrix: tensor([[2797.,   21.],\n",
                        "        [ 165.,    5.]])\n",
                        "Test atelectasis accuracy: 0.9364123344421387\n",
                        "Test atelectasis precision: 0.9928951859474182\n",
                        "Test atelectasis recall: 0.9426644444465637\n",
                        "Test atelectasis auroc: 0.49877557005645573\n",
                        "Test atelectasis auc: 0.0024953139945864677\n",
                        "Test atelectasis confusion_matrix: tensor([[   3.,   20.],\n",
                        "        [ 170., 2795.]])\n",
                        "Test pleural_effusion accuracy: 0.7319276928901672\n",
                        "Test pleural_effusion precision: 0.7018970251083374\n",
                        "Test pleural_effusion recall: 0.27263158559799194\n",
                        "Test pleural_effusion auroc: 0.7262424461546407\n",
                        "Test pleural_effusion auc: 0.4117361903190613\n",
                        "Test pleural_effusion confusion_matrix: tensor([[1928.,  110.],\n",
                        "        [ 691.,  259.]])\n",
                        "Test multilabel_accuracy: 0.289825975894928\n",
                        "Test multilabel_auprc: 0.5603724718093872\n",
                        "Test mcc: 0.6294410228729248\n"
                    ]
                }
            ],
            "source": [
                "res = model.test(test_dataset=test_dataset,name=name, test_labels=test_labels)\n",
                "# append two columns: confidence_threshold and test_set to the result\n",
                "res[\"confidence_threshold\"] = params[\"confidence_threshold\"]\n",
                "res[\"test_set\"] = csv_file\n",
                "res[\"family\"] = family\n",
                "\n",
                "result = pd.concat([result, res], ignore_index=True)\n",
                "# write result to excel\n",
                "with pd.ExcelWriter(result_xls, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
                "    result.to_excel(writer, sheet_name=\"Sheet1\", index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Two stage model - AP/PA Split\n",
                "\n",
                "Testing of the two stage model with ap/pa split.\n",
                "\n",
                "## Define model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Class weights: [np.float64(3.0794415416798357), np.float64(2.9784333407608736), np.float64(3.6347624053323777), np.float64(5.775081722705364), np.float64(1.5531789841019434)]\n",
                        "Test dataset size: 2988\n"
                    ]
                }
            ],
            "source": [
                "params_transform = {\n",
                "    \"resize\": (256, 256),\n",
                "}\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize(params_transform[\"resize\"]),\n",
                "    transforms.ToTensor(),\n",
                "])\n",
                "\n",
                "targets = {\n",
                "            # \"sex\": 1,\n",
                "            # \"age\": 2,\n",
                "            # \"frontal/lateral\": 3,\n",
                "            # \"ap/pa\": 4,\n",
                "            # \"no_finding\": 5,\n",
                "            # \"enlarged_cardiomediastinum\": 6,\n",
                "            \"cardiomegaly\": 7,\n",
                "            # \"lung_opacity\": 8,\n",
                "            # \"lung_lesion\": 9,\n",
                "            \"edema\": 10,\n",
                "            \"consolidation\": 11,\n",
                "            # \"pneumonia\": 12,\n",
                "            \"atelectasis\": 13,\n",
                "            # \"pneumothorax\": 14,\n",
                "            \"pleural_effusion\": 15,\n",
                "            # \"pleural_other\": 16,\n",
                "            # \"fracture\": 17,\n",
                "            # \"support_devices\": 18,\n",
                "            # \"fronal_lateral_map\": 21,\n",
                "            # \"ap/pa map\": 22,\n",
                "        }\n",
                "\n",
                "# If you want to test the model on a subset of the labels you can specify the labels here. The labels are the relative positions compared to the labels used in the training.\n",
                "test_labels = None\n",
                "\n",
                "csv_file = \"data/90_5_5/fr_test_balanced.csv\"\n",
                "\n",
                "test_dataset = CheXpertDataset(\n",
                "    csv_file=csv_file,\n",
                "    root_dir=\"../image_data/\",\n",
                "    targets=targets,\n",
                "    transform=transform,\n",
                ")\n",
                "print(f\"Test dataset size: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    \"train_transfrom\": params_transform,\n",
                "    \"lr\": 0.001,\n",
                "    \"save_epoch\": 5,\n",
                "    \"batch_size\": 256,\n",
                "    \"num_epochs\": 100,\n",
                "    \"input_channels\": 1,\n",
                "    \"optimizer\": \"adam\",\n",
                "    \"num_workers\": 0,\n",
                "    \"loss_fn\": \"multilabel_focal_loss\",\n",
                "    \"metrics\": [\"accuracy\",\n",
                "            \"precision\",\n",
                "            \"recall\",\n",
                "            \"confusion_matrix\",\n",
                "            \"auc\",\n",
                "            \"auroc\",\n",
                "            \"multilabel_accuracy\",\n",
                "            \"multilabel_auprc\",\n",
                "            \"multilabel_precision_recall_curve\",\n",
                "            \"mcc\"],\n",
                "    \"confidence_threshold\": 0.5,\n",
                "}\n",
                "\n",
                "name = \"best_model_not_pretrained\"\n",
                "\n",
                "family = \"Two_Stage_AP/PA\"\n",
                "\n",
                "weights_first_stage = \"final_models/final_90_5_5/ap-pa_split.pth\"\n",
                "weights_second_stage_ap = \"final_models/final_90_5_5/AP_Not_Pretrained/best_model_mcc_36.pth\"\n",
                "weights_second_stage_pa = \"final_models/final_90_5_5/PA_Not_Pretrained/best_model_mcc_33.pth\"\n",
                "\n",
                "weights = f\"First: {weights_first_stage}, Second AP: {weights_second_stage_ap}, Second PA: {weights_second_stage_pa}\"\n",
                "\n",
                "model = TwoStageModelAPPA(\n",
                "    params=params, \n",
                "    model_ap_pa_classification=weights_first_stage, \n",
                "    model_ap=weights_second_stage_ap, \n",
                "    model_pa=weights_second_stage_pa,\n",
                "    targets=targets,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing two stage model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:08<00:00,  1.42it/s, test_loss=0.113272]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test loss: 0.1132721285932163\n",
                        "Test cardiomegaly accuracy: 0.8785140514373779\n",
                        "Test cardiomegaly precision: 0.41040462255477905\n",
                        "Test cardiomegaly recall: 0.21385541558265686\n",
                        "Test cardiomegaly auroc: 0.7739455563216723\n",
                        "Test cardiomegaly auc: 0.27219656109809875\n",
                        "Test cardiomegaly confusion_matrix: tensor([[2554.,  102.],\n",
                        "        [ 261.,   71.]])\n",
                        "Test edema accuracy: 0.6957831382751465\n",
                        "Test edema precision: 0.8928571343421936\n",
                        "Test edema recall: 0.7428571581840515\n",
                        "Test edema auroc: 0.5920377804014167\n",
                        "Test edema auc: 0.03415004909038544\n",
                        "Test edema confusion_matrix: tensor([[ 129.,  234.],\n",
                        "        [ 675., 1950.]])\n",
                        "Test consolidation accuracy: 0.9206827282905579\n",
                        "Test consolidation precision: 0.08888889104127884\n",
                        "Test consolidation recall: 0.019999999552965164\n",
                        "Test consolidation auroc: 0.6075609756097561\n",
                        "Test consolidation auc: 0.04190339148044586\n",
                        "Test consolidation confusion_matrix: tensor([[2747.,   41.],\n",
                        "        [ 196.,    4.]])\n",
                        "Test atelectasis accuracy: 0.9099732041358948\n",
                        "Test atelectasis precision: 0.9912472367286682\n",
                        "Test atelectasis recall: 0.9173135161399841\n",
                        "Test atelectasis auroc: 0.4913668579142761\n",
                        "Test atelectasis auc: 0.003878055140376091\n",
                        "Test atelectasis confusion_matrix: tensor([[1.0000e+00, 2.4000e+01],\n",
                        "        [2.4500e+02, 2.7180e+03]])\n",
                        "Test pleural_effusion accuracy: 0.7008032202720642\n",
                        "Test pleural_effusion precision: 0.7118279337882996\n",
                        "Test pleural_effusion recall: 0.30339139699935913\n",
                        "Test pleural_effusion auroc: 0.7959772461414545\n",
                        "Test pleural_effusion auc: 0.2992308735847473\n",
                        "Test pleural_effusion confusion_matrix: tensor([[1763.,  134.],\n",
                        "        [ 760.,  331.]])\n",
                        "Test multilabel_accuracy: 0.3443775177001953\n",
                        "Test multilabel_auprc: 0.595714271068573\n",
                        "Test mcc: 0.6546882390975952\n"
                    ]
                }
            ],
            "source": [
                "res = model.test(test_dataset=test_dataset,name=name, test_labels=test_labels)\n",
                "# append two columns: confidence_threshold and test_set to the result\n",
                "res[\"confidence_threshold\"] = params[\"confidence_threshold\"]\n",
                "res[\"test_set\"] = csv_file\n",
                "res[\"family\"] = family\n",
                "\n",
                "result = pd.concat([result, res], ignore_index=True)\n",
                "# write result to excel\n",
                "with pd.ExcelWriter(result_xls, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
                "    result.to_excel(writer, sheet_name=\"Sheet1\", index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Two stage model - Frontal/Lateral Split\n",
                "\n",
                "Testing of the two stage model with fronal/lateral split.\n",
                "\n",
                "## Define model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Class weights: [np.float64(3.1172684010519984), np.float64(2.86429275487946), np.float64(3.807984255408364), np.float64(5.859138095502676), np.float64(1.7632622291880837)]\n",
                        "Test dataset size: 2988\n"
                    ]
                }
            ],
            "source": [
                "params_transform = {\n",
                "    \"resize\": (256, 256),\n",
                "}\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize(params_transform[\"resize\"]),\n",
                "    transforms.ToTensor(),\n",
                "])\n",
                "\n",
                "targets = {\n",
                "            # \"sex\": 1,\n",
                "            # \"age\": 2,\n",
                "            # \"frontal/lateral\": 3,\n",
                "            # \"ap/pa\": 4,\n",
                "            # \"no_finding\": 5,\n",
                "            # \"enlarged_cardiomediastinum\": 6,\n",
                "            \"cardiomegaly\": 7,\n",
                "            # \"lung_opacity\": 8,\n",
                "            # \"lung_lesion\": 9,\n",
                "            \"edema\": 10,\n",
                "            \"consolidation\": 11,\n",
                "            # \"pneumonia\": 12,\n",
                "            \"atelectasis\": 13,\n",
                "            # \"pneumothorax\": 14,\n",
                "            \"pleural_effusion\": 15,\n",
                "            # \"pleural_other\": 16,\n",
                "            # \"fracture\": 17,\n",
                "            # \"support_devices\": 18,\n",
                "            # \"fronal_lateral_map\": 21,\n",
                "            # \"ap/pa map\": 22,\n",
                "        }\n",
                "\n",
                "# If you want to test the model on a subset of the labels you can specify the labels here. The labels are the relative positions compared to the labels used in the training.\n",
                "test_labels = None\n",
                "\n",
                "csv_file = \"data/90_5_5/fr_lat_test_balanced.csv\"\n",
                "\n",
                "test_dataset = CheXpertDataset(\n",
                "    csv_file=csv_file,\n",
                "    root_dir=\"../image_data/\",\n",
                "    targets=targets,\n",
                "    transform=transform,\n",
                ")\n",
                "print(f\"Test dataset size: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    \"train_transfrom\": params_transform,\n",
                "    \"lr\": 0.001,\n",
                "    \"save_epoch\": 5,\n",
                "    \"batch_size\": 256,\n",
                "    \"num_epochs\": 100,\n",
                "    \"input_channels\": 1,\n",
                "    \"optimizer\": \"adam\",\n",
                "    \"num_workers\": 0,\n",
                "    # BCE with Sigmoid activation function\n",
                "    \"loss_fn\": \"torch.nn.BCEWithLogitsLoss()\",\n",
                "    # For multilabel: MultiLabelSoftMarginLoss\n",
                "    \"metrics\": [\"accuracy\",\n",
                "            \"precision\",\n",
                "            \"recall\",\n",
                "            \"confusion_matrix\",\n",
                "            \"auc\",\n",
                "            \"auroc\",\n",
                "            \"multilabel_accuracy\",\n",
                "            \"multilabel_auprc\",\n",
                "            \"multilabel_precision_recall_curve\",\n",
                "            \"mcc\"],\n",
                "    \"confidence_threshold\": 0.5,\n",
                "}\n",
                "\n",
                "name = \"best_model_auprc_not_pretrained\"\n",
                "\n",
                "family = \"Two_Stage_Frontal/Lateral\"\n",
                "\n",
                "weights_first_stage = \"final_models/final_90_5_5/fr-lat_split.pth\"\n",
                "weights_second_stage_frontal = \"final_models/final_90_5_5/Fr_Not_Pretrained/best_model_39.pth\"\n",
                "weights_second_stage_lateral = \"final_models/final_90_5_5/Lat_Not_Pretrained/best_model_26.pth\"\n",
                "\n",
                "weights = f\"First: {weights_first_stage}, Second Frontal: {weights_second_stage_frontal}, Second Lateral: {weights_second_stage_lateral}\"\n",
                "\n",
                "model = TwoStageModelFrontalLateral(\n",
                "    params=params, \n",
                "    model_frontal_lateral_classification=weights_first_stage,\n",
                "    model_frontal=weights_second_stage_frontal,\n",
                "    model_lateral=weights_second_stage_lateral,\n",
                "    targets=targets,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing two stage model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [00:08<00:00,  1.34it/s, test_loss=0.428395]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test loss: 0.4283947436541263\n",
                        "Test cardiomegaly accuracy: 0.8942436575889587\n",
                        "Test cardiomegaly precision: 0.5242718458175659\n",
                        "Test cardiomegaly recall: 0.1682243049144745\n",
                        "Test cardiomegaly auroc: 0.7706127855513388\n",
                        "Test cardiomegaly auc: 0.21317696571350098\n",
                        "Test cardiomegaly confusion_matrix: tensor([[2618.,   49.],\n",
                        "        [ 267.,   54.]])\n",
                        "Test edema accuracy: 0.45582330226898193\n",
                        "Test edema precision: 0.9027661085128784\n",
                        "Test edema recall: 0.4163123369216919\n",
                        "Test edema auroc: 0.58931912584214\n",
                        "Test edema auc: 0.04035171866416931\n",
                        "Test edema confusion_matrix: tensor([[ 285.,  116.],\n",
                        "        [1510., 1077.]])\n",
                        "Test consolidation accuracy: 0.9390897154808044\n",
                        "Test consolidation precision: 0.0714285746216774\n",
                        "Test consolidation recall: 0.0058823530562222\n",
                        "Test consolidation auroc: 0.632334154385672\n",
                        "Test consolidation auc: 0.07967347651720047\n",
                        "Test consolidation confusion_matrix: tensor([[2.8050e+03, 1.3000e+01],\n",
                        "        [1.6900e+02, 1.0000e+00]])\n",
                        "Test atelectasis accuracy: 0.9538152813911438\n",
                        "Test atelectasis precision: 0.9926803708076477\n",
                        "Test atelectasis recall: 0.9605396389961243\n",
                        "Test atelectasis auroc: 0.5763032480387125\n",
                        "Test atelectasis auc: 0.003186500631272793\n",
                        "Test atelectasis confusion_matrix: tensor([[2.0000e+00, 2.1000e+01],\n",
                        "        [1.1700e+02, 2.8480e+03]])\n",
                        "Test pleural_effusion accuracy: 0.7446452379226685\n",
                        "Test pleural_effusion precision: 0.7286063432693481\n",
                        "Test pleural_effusion recall: 0.31368422508239746\n",
                        "Test pleural_effusion auroc: 0.8189106967615309\n",
                        "Test pleural_effusion auc: 0.34853336215019226\n",
                        "Test pleural_effusion confusion_matrix: tensor([[1927.,  111.],\n",
                        "        [ 652.,  298.]])\n",
                        "Test multilabel_accuracy: 0.24564926326274872\n",
                        "Test multilabel_auprc: 0.5941752791404724\n",
                        "Test mcc: 0.6195433139801025\n"
                    ]
                }
            ],
            "source": [
                "res = model.test(test_dataset=test_dataset,name=name, test_labels=test_labels)\n",
                "# append two columns: confidence_threshold and test_set to the result\n",
                "res[\"confidence_threshold\"] = params[\"confidence_threshold\"]\n",
                "res[\"test_set\"] = csv_file\n",
                "res[\"family\"] = family\n",
                "\n",
                "result = pd.concat([result, res], ignore_index=True)\n",
                "# write result to excel\n",
                "with pd.ExcelWriter(result_xls, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
                "    result.to_excel(writer, sheet_name=\"Sheet1\", index=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Three stage model - Lateral/AP/PA Split\n",
                "\n",
                "Testing of the three stage model. First stage is the frontal/lateral split, second stage is the ap/pa split and third stage is the multilabel classification of the images.\n",
                "\n",
                "## Define model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Class weights: [np.float64(3.0794415416798357), np.float64(2.9201511490782153), np.float64(3.6933892622193722), np.float64(5.873849311314257), np.float64(1.674130760975404)]\n",
                        "Test dataset size: 4482\n"
                    ]
                }
            ],
            "source": [
                "params_transform = {\n",
                "    \"resize\": (256, 256),\n",
                "}\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize(params_transform[\"resize\"]),\n",
                "    transforms.ToTensor(),\n",
                "])\n",
                "\n",
                "targets = {\n",
                "            # \"sex\": 1,\n",
                "            # \"age\": 2,\n",
                "            # \"frontal/lateral\": 3,\n",
                "            # \"ap/pa\": 4,\n",
                "            # \"no_finding\": 5,\n",
                "            # \"enlarged_cardiomediastinum\": 6,\n",
                "            \"cardiomegaly\": 7,\n",
                "            # \"lung_opacity\": 8,\n",
                "            # \"lung_lesion\": 9,\n",
                "            \"edema\": 10,\n",
                "            \"consolidation\": 11,\n",
                "            # \"pneumonia\": 12,\n",
                "            \"atelectasis\": 13,\n",
                "            # \"pneumothorax\": 14,\n",
                "            \"pleural_effusion\": 15,\n",
                "            # \"pleural_other\": 16,\n",
                "            # \"fracture\": 17,\n",
                "            # \"support_devices\": 18,\n",
                "            # \"fronal_lateral_map\": 21,\n",
                "            # \"ap/pa map\": 22,\n",
                "        }\n",
                "\n",
                "# If you want to test the model on a subset of the labels you can specify the labels here. The labels are the relative positions compared to the labels used in the training.\n",
                "test_labels = None\n",
                "\n",
                "csv_file = \"data/90_5_5/test_balanced.csv\"\n",
                "\n",
                "test_dataset = CheXpertDataset(\n",
                "    csv_file=csv_file,\n",
                "    root_dir=\"../image_data/\",\n",
                "    targets=targets,\n",
                "    transform=transform,\n",
                ")\n",
                "print(f\"Test dataset size: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {},
            "outputs": [],
            "source": [
                "params = {\n",
                "    \"train_transfrom\": params_transform,\n",
                "    \"lr\": 0.001,\n",
                "    \"save_epoch\": 5,\n",
                "    \"batch_size\": 256,\n",
                "    \"num_epochs\": 100,\n",
                "    \"input_channels\": 1,\n",
                "    \"optimizer\": \"adam\",\n",
                "    \"num_workers\": 0,\n",
                "    \"loss_fn\": \"multilabel_focal_loss\",\n",
                "    \"metrics\": [\"accuracy\",\n",
                "            \"precision\",\n",
                "            \"recall\",\n",
                "            \"confusion_matrix\",\n",
                "            \"auc\",\n",
                "            \"auroc\",\n",
                "            \"multilabel_accuracy\",\n",
                "            \"multilabel_auprc\",\n",
                "            \"multilabel_precision_recall_curve\",\n",
                "            \"mcc\"],\n",
                "    \"confidence_threshold\": 0.5,\n",
                "}\n",
                "\n",
                "name = \"best_model_mcc_not_pretrained\"\n",
                "\n",
                "family = \"Three_Stage\"\n",
                "\n",
                "\n",
                "weights_fr_lat_classification = \"final_models/final_90_5_5/fr-lat_split.pth\"\n",
                "weights_ap_pa_classification = \"final_models/final_90_5_5/ap-pa_split.pth\"\n",
                "weights_frontal_ap = \"final_models/final_90_5_5/AP_Not_Pretrained/best_model_mcc_36.pth\"\n",
                "weights_frontal_pa = \"final_models/final_90_5_5/PA_Not_Pretrained/best_model_mcc_33.pth\"\n",
                "weights_lateral = \"final_models/final_90_5_5/Lat_Not_Pretrained/best_model_mcc_37.pth\"\n",
                "\n",
                "weights = f\"Fr/Lat Classification: {weights_fr_lat_classification}, AP/PA Classification: {weights_ap_pa_classification}, Frontal AP: {weights_frontal_ap}, Frontal PA: {weights_frontal_pa}, Lateral: {weights_lateral}\"\n",
                "\n",
                "\n",
                "model = ThreeStageModelFrontalLateralAPPA(\n",
                "    params=params, \n",
                "    model_frontal_lateral_classification = weights_fr_lat_classification,\n",
                "    model_frontal_ap_pa_classification = weights_ap_pa_classification,\n",
                "    model_frontal_ap = weights_frontal_ap,\n",
                "    model_frontal_pa = weights_frontal_pa,\n",
                "    model_lateral = weights_lateral,\n",
                "    targets=targets,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Testing three stage model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:13<00:00,  1.31it/s, test_loss=0.106047]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Test loss: 0.10604689982626013\n",
                        "Test cardiomegaly accuracy: 0.8603302240371704\n",
                        "Test cardiomegaly precision: 0.3483412265777588\n",
                        "Test cardiomegaly recall: 0.29518070816993713\n",
                        "Test cardiomegaly auroc: 0.7535034717181981\n",
                        "Test cardiomegaly auc: 0.2508052587509155\n",
                        "Test cardiomegaly confusion_matrix: tensor([[3709.,  275.],\n",
                        "        [ 351.,  147.]])\n",
                        "Test edema accuracy: 0.7295849919319153\n",
                        "Test edema precision: 0.8829877972602844\n",
                        "Test edema recall: 0.7953440546989441\n",
                        "Test edema auroc: 0.5855516669144504\n",
                        "Test edema auc: 0.03464272618293762\n",
                        "Test edema confusion_matrix: tensor([[ 161.,  412.],\n",
                        "        [ 800., 3109.]])\n",
                        "Test consolidation accuracy: 0.9107541441917419\n",
                        "Test consolidation precision: 0.08571428805589676\n",
                        "Test consolidation recall: 0.0422535203397274\n",
                        "Test consolidation auroc: 0.6089527877124586\n",
                        "Test consolidation auc: 0.026301827281713486\n",
                        "Test consolidation confusion_matrix: tensor([[4070.,  128.],\n",
                        "        [ 272.,   12.]])\n",
                        "Test atelectasis accuracy: 0.9355198740959167\n",
                        "Test atelectasis precision: 0.992189347743988\n",
                        "Test atelectasis recall: 0.9424460530281067\n",
                        "Test atelectasis auroc: 0.5450764388489209\n",
                        "Test atelectasis auc: 0.0024736870545893908\n",
                        "Test atelectasis confusion_matrix: tensor([[1.0000e+00, 3.3000e+01],\n",
                        "        [2.5600e+02, 4.1920e+03]])\n",
                        "Test pleural_effusion accuracy: 0.7248995900154114\n",
                        "Test pleural_effusion precision: 0.6340996026992798\n",
                        "Test pleural_effusion recall: 0.43754130601882935\n",
                        "Test pleural_effusion auroc: 0.7813513376937319\n",
                        "Test pleural_effusion auc: 0.4518130421638489\n",
                        "Test pleural_effusion confusion_matrix: tensor([[2587.,  382.],\n",
                        "        [ 851.,  662.]])\n",
                        "Test multilabel_accuracy: 0.38219544291496277\n",
                        "Test multilabel_auprc: 0.5810900330543518\n",
                        "Test mcc: 0.666248083114624\n"
                    ]
                }
            ],
            "source": [
                "res = model.test(test_dataset=test_dataset,name=name, test_labels=test_labels)\n",
                "# append two columns: confidence_threshold and test_set to the result\n",
                "res[\"confidence_threshold\"] = params[\"confidence_threshold\"]\n",
                "res[\"test_set\"] = csv_file\n",
                "res[\"family\"] = family\n",
                "\n",
                "result = pd.concat([result, res], ignore_index=True)\n",
                "# write result to excel\n",
                "with pd.ExcelWriter(result_xls, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
                "    result.to_excel(writer, sheet_name=\"Sheet1\", index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "personalized_ml",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
